{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ffc3d6-add1-412f-a998-8e244771b603",
   "metadata": {},
   "source": [
    "Make a python script that can automate the process for creating publication entries. If possible, the script should get the author names, article title, journal name, publication date, and abstract and compile it into a templated markdown file for insertion into the publications page.\n",
    "\n",
    "For the publications: we can stick with pubs starting from 2018 or 2019 since that's when the lab started up. There will be a relatively large number of publications here, so it would probably be ideal if this could be automated to some degree (like a script that could automatically parse a google scholar entry or DOI into a properly formatted markdown file that matches the template for the wowchemy publications page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad290666-1eb0-4f85-9eeb-de18be5fc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import json\n",
    "\n",
    "name_to_account = {\n",
    "    'Tod A. Pascal': 'admin',\n",
    "}\n",
    "\n",
    "def replace_with_dictionary(array, dictionary):\n",
    "    # Iterate over each string in the array\n",
    "    for i in range(len(array)):\n",
    "        # If the string is a key in the dictionary, replace it with the corresponding value\n",
    "        if array[i] in dictionary:\n",
    "            array[i] = dictionary[array[i]]\n",
    "    return array\n",
    "\n",
    "def fetch_data(doi):\n",
    "    \"\"\"Fetch publication data from CrossRef API.\"\"\"\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['message']\n",
    "    else:\n",
    "        print(\"Failed to fetch data.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def create_files(pub_data, dir_name):\n",
    "    \"\"\"Create directory and files based on publication data.\"\"\"\n",
    "    # Ensure valid filenames\n",
    "    directory = \"out\"\n",
    "    valid_dir_name = os.path.join(directory, dir_name.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace('\"', '').replace(':', '_').replace('?', ''))\n",
    "    os.makedirs(valid_dir_name, exist_ok=True)\n",
    "\n",
    "    # Extracting and formatting author list to include only first names\n",
    "    authors_source = [f\"{author.get('given', '')} {author.get('family', '')}\" for author in pub_data.get('author', [])]\n",
    "    authors = authors_source.copy()\n",
    "    authors = replace_with_dictionary(authors, name_to_account)\n",
    "    authors_md = \"\\n- \".join([\"\"] + authors)  # Markdown list format\n",
    "    \n",
    "    # Format publication date correctly\n",
    "    pub_date_parts = pub_data.get('published-print', pub_data.get('published-online', {'date-parts': [[0]]}))['date-parts'][0]\n",
    "    if len(pub_date_parts) == 3:  # Full date available\n",
    "        formatted_pub_date = f\"{pub_date_parts[0]:04d}-{pub_date_parts[1]:02d}-{pub_date_parts[2]:02d}T00:00:00Z\"\n",
    "    elif len(pub_date_parts) == 2:  # Only year and month available\n",
    "        formatted_pub_date = f\"{pub_date_parts[0]:04d}-{pub_date_parts[1]:02d}-01T00:00:00Z\"\n",
    "    else:  # Only year available\n",
    "        formatted_pub_date = f\"{pub_date_parts[0]:04d}-01-01T00:00:00Z\"\n",
    "\n",
    "    # Edge Case during parsing:\n",
    "    publication = pub_data.get('container-title', [''])\n",
    "    if len(publication) == 0:\n",
    "        publication = ['']\n",
    "    # Index.md content\n",
    "    index_content = f\"\"\"---\n",
    "title: \"{pub_data.get('title', [''])[0]}\"\n",
    "authors:{authors_md}\n",
    "date: \"{formatted_pub_date}\"\n",
    "doi: \"{pub_data.get('DOI', '')}\"\n",
    "abstract: \"{pub_data.get('abstract', '').replace('\\n', ' ')}\"\n",
    "url_pdf: \"{pub_data.get('URL', '')}\"\n",
    "publication: \"{publication[0]}\"\n",
    "publication_types: [\"article-journal\"]\n",
    "---\n",
    "\n",
    "Add the publication's full text or supplementary notes here.\n",
    "\"\"\"\n",
    "    with open(os.path.join(valid_dir_name, \"index.md\"), \"w\", encoding='utf-8') as f:\n",
    "        f.write(index_content)\n",
    "\n",
    "    # Prepare full names for citation\n",
    "    bib_authors = \", \".join(authors_source)\n",
    "    bib_content = f\"\"\"@article{{{pub_data.get('DOI', '').replace('/', '_')},\n",
    "  title = {{{pub_data.get('title', [''])[0]}}},\n",
    "  author= {{{bib_authors}}},\n",
    "  journal = {{{publication[0]}}},\n",
    "  year    = {pub_date_parts[0]},\n",
    "  volume  = {pub_data.get('volume', '')},\n",
    "  number  = {pub_data.get('issue', '')},\n",
    "  doi     = {{{pub_data.get('DOI', '')}}},\n",
    "  url     = {{{pub_data.get('URL', '')}}}\n",
    "}}\n",
    "\"\"\"\n",
    "    with open(os.path.join(valid_dir_name, \"cite.bib\"), \"w\", encoding='utf-8') as f:\n",
    "        f.write(bib_content)\n",
    "\n",
    "    print(f\"Files generated in directory: {valid_dir_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     if len(sys.argv) != 2:\n",
    "#         print(\"Usage: python fetch_pub_data.py <DOI>\")\n",
    "#         sys.exit(1)\n",
    "    \n",
    "#     doi = sys.argv[1]\n",
    "#     pub_data = fetch_data(doi)\n",
    "\n",
    "#     # Use title for directory name, or DOI if title is unavailable\n",
    "#     dir_name = pub_data.get('DOI').split('/')[1]\n",
    "#     create_files(pub_data, dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e104375-0868-40cd-8bab-b4bf3a797caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files generated in directory: out/bi901283p\n"
     ]
    }
   ],
   "source": [
    "doi = \"10.1021/bi901283p\"\n",
    "pub_data = fetch_data(doi)\n",
    "dir_name = pub_data.get('DOI').split('/')[1]\n",
    "create_files(pub_data, dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1b5a2-279b-46c6-a196-f0fa7c48f2d3",
   "metadata": {},
   "source": [
    "Script to fetch all DOIs by an author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55da9c03-9353-4d78-9997-6f29a7788771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers by Tod A. Pascal:\n",
      "- DOI: 10.1038/s41467-023-37857-3\n",
      "- DOI: 10.21203/rs.3.rs-1683269/v1\n",
      "- DOI: 10.1021/jp410861h\n",
      "- DOI: 10.1021/jp309693d\n",
      "- DOI: 10.1021/acs.jpclett.1c02609\n",
      "- DOI: 10.1016/j.cmpb.2011.04.006\n",
      "- DOI: 10.1039/c6cp03940e\n",
      "- DOI: 10.1039/c4cp05316h\n",
      "- DOI: 10.1149/ma2022-01381691mtgabs\n",
      "- DOI: 10.1063/5.0054314\n",
      "- DOI: 10.1039/d2nr05732h\n",
      "- DOI: 10.1021/jz200453u\n",
      "- DOI: 10.1007/s40262-012-0014-9\n",
      "- DOI: 10.1063/1.3456543\n",
      "- DOI: 10.1073/pnas.1108073108\n",
      "- DOI: 10.1149/ma2014-02/1/17\n",
      "- DOI: 10.1149/ma2017-01/43/1984\n",
      "- DOI: 10.1016/j.commatsci.2012.12.024\n",
      "- DOI: 10.2139/ssrn.236033\n",
      "- DOI: 10.1149/ma2016-03/2/422\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# def find_papers_by_author(author_name):\n",
    "#     # Construct the CrossRef API URL for querying papers by author\n",
    "#     url = f\"https://api.crossref.org/works?query.author={author_name}\"\n",
    "    \n",
    "#     # Make a GET request to the CrossRef API\n",
    "#     response = requests.get(url)\n",
    "    \n",
    "#     # Check if the request was successful (status code 200)\n",
    "#     if response.status_code == 200:\n",
    "#         # Parse the JSON response\n",
    "#         data = response.json()\n",
    "        \n",
    "#         # Extract DOIs from the API response\n",
    "#         dois = [item['DOI'] for item in data['message']['items']]\n",
    "        \n",
    "#         return dois\n",
    "#     else:\n",
    "#         # If request was not successful, print error message\n",
    "#         print(\"Error fetching papers:\", response.status_code)\n",
    "#         return None\n",
    "\n",
    "# # Example usage:\n",
    "# author_name = \"Tod A. Pascal\"\n",
    "# paper_dois = find_papers_by_author(author_name)\n",
    "# if paper_dois:\n",
    "#     print(\"Papers by\", author_name + \":\")\n",
    "#     for doi in paper_dois:\n",
    "#         print(\"- DOI:\", doi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d804b6cc-f0ab-49b9-b34a-231d0b359690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files generated in directory: s41467-023-37857-3\n",
      "Files generated in directory: rs.3.rs-1683269\n",
      "Files generated in directory: jp410861h\n",
      "Files generated in directory: jp309693d\n",
      "Files generated in directory: acs.jpclett.1c02609\n",
      "Files generated in directory: j.cmpb.2011.04.006\n",
      "Files generated in directory: c6cp03940e\n",
      "Files generated in directory: c4cp05316h\n",
      "Files generated in directory: ma2022-01381691mtgabs\n",
      "Files generated in directory: 5.0054314\n",
      "Files generated in directory: d2nr05732h\n",
      "Files generated in directory: jz200453u\n",
      "Files generated in directory: s40262-012-0014-9\n",
      "Files generated in directory: 1.3456543\n",
      "Files generated in directory: pnas.1108073108\n",
      "Files generated in directory: ma2014-02\n",
      "Files generated in directory: ma2017-01\n",
      "Files generated in directory: j.commatsci.2012.12.024\n",
      "Files generated in directory: ssrn.236033\n",
      "Files generated in directory: ma2016-03\n"
     ]
    }
   ],
   "source": [
    "for doi in paper_dois:\n",
    "    pub_data = fetch_data(doi)\n",
    "    dir_name = pub_data.get('DOI').split('/')[1]\n",
    "    create_files(pub_data, dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb7f994-ea71-4e3d-b8ea-767292ce51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main versions of papers:\n",
      "Paper 004: 004.jbc-8829-36.pdf\n",
      "Paper 013: 013.nl104227t.pdf\n",
      "Paper 003: 003.NanoSciNanoTech.707.pdf\n",
      "Paper 059: 059.s41467-021-23603-0.pdf\n",
      "Paper 034: 034.c5cp02951a.pdf\n",
      "Paper 044: 044.jacs.7b11891.pdf\n",
      "Paper 055: 055.s41560-021-00783-z.pdf\n",
      "Paper 079: 079.acs.jpcb.2c08843.ms.pdf\n",
      "Paper 032: 032.nature14327-s1.pdf\n",
      "Paper 068: 068.acsenergylett.1c02723.pdf\n",
      "Paper 085: 085.acsami.3c07224.si.pdf\n",
      "Paper 069: 069.d1ee03422g.pdf\n",
      "Paper 012: 012.jz200453u.pdf\n",
      "Paper 054: 054.1-s2.0-S1369702120303382-main.pdf\n",
      "Paper 087: 087.jacs.3c05093.si.pdf\n",
      "Paper 051: 051.acs.jpclett.9b01835.pdf\n",
      "Paper 080: 080.acs.jpclett.2c03942.si.1.pdf\n",
      "Paper 067: 067.1-s2.0-S2666386421004537-main.pdf\n",
      "Paper 008: 008.JChemPhys_133_134114.pdf\n",
      "Paper 046: 046.J. Electrochem. Soc.-2018-Wang-A3487-95.pdf\n",
      "Paper 061: 061.acs.nanolett.1c01502.pdf\n",
      "Paper 070: 070.acs.nanolett.2c00047.si.pdf\n",
      "Paper 083: 083.acs.nanolett.3c01825.si.pdf\n",
      "Paper 048: 048.jacs.8b09743.pdf\n",
      "Paper 040: 040.nlE7b00249.pdf\n",
      "Paper 006: 006.BioChem.bi901283p.pdf\n",
      "Paper 017: 017.jp209541e.pdf\n",
      "Paper 042: 042.s41467-017-02410-6-SI.pdf\n",
      "Paper 053: 053.acsenergylett.0c00643.si.pdf\n",
      "Paper 064: 064.acs.jpclett.1c02609.si.pdf\n",
      "Paper 084: 084.acsami.3c09627.pdf\n",
      "Paper 082: 082.s41563-023-01535-y_ESM.pdf\n",
      "Paper 023: 023.025248JCP.pdf\n",
      "Paper 038: 038.JECS-2017-Wujcik-A18-27.pdf\n",
      "Paper 009: 009.jbc-37753-61.pdf\n",
      "Paper 002: 002.BioPhysJ-2006-1463.pdf\n",
      "Paper 071: 071.acs.jpclett.2c00770.pdf\n",
      "Paper 030: 030.science.831.SM.pdf\n",
      "Paper 078: 078.d2nr05732h.ms.pdf\n",
      "Paper 015: 015.jz200760n.pdf\n",
      "Paper 001: 001.nar-6047.full.pdf\n",
      "Paper 058: 058.eabe2265.full.pdf\n",
      "Paper 018: 018.jz201612y.pdf\n",
      "Paper 041: 041.acs.jpcc.7b05153.pdf\n",
      "Paper 036: 036.c6cp03940e1.pdf\n",
      "Paper 027: 027.jz500260s.pdf\n",
      "Paper 072: 072.pnas.2200392119.pdf\n",
      "Paper 021: 021.jp306473u.pdf\n",
      "Paper 022: 022.jp309693d.pdf\n",
      "Paper 063: 063.PhysRevLett.127.096801.pdf\n",
      "Paper 050: 050.1.5109468.pdf\n",
      "Paper 074: 074.acs.chemmater.2c00292.pdf\n",
      "Paper 020: 020.jp301610b.pdf\n",
      "Paper 014: 014.ct200211b.pdf\n",
      "Paper 026: 026.066401JCP.pdf\n",
      "Paper 016: 016.pnas.1108073108.pdf\n",
      "Paper 011: 011.c0cp01549k.pdf\n",
      "Paper 037: 037.jp6b04264.pdf\n",
      "Paper 047: 047.qt3xn0326x.pdf\n",
      "Paper 005: 005.jbc-15835-46.pdf\n",
      "Paper 043: 043.PhysRevLett.120.023901.pdf\n",
      "Paper 066: 066.PhysRevLett.127.237402.pdf\n",
      "Paper 031: 031.C4CP05316H.pdf\n",
      "Paper 073: 073.acsnano.2c04595.pdf\n",
      "Paper 088: 088.anie202316786-ms.pdf\n",
      "Paper 060: 060.jcp5.0054314.pdf\n",
      "Paper 035: 035.nl5b02078.pdf\n",
      "Paper 052: 052.j.cplett.2019.136811.pdf\n",
      "Paper 075: 075.acs.jpclett.2c01020.pdf\n",
      "Paper 007: 007.cphc_201000528_sm_miscellaneous_information.pdf\n",
      "Paper 081: 081.s41467-023-37857-3.pdf\n",
      "Paper 039: 039.c6cp06889h.pdf\n",
      "Paper 049: 049.acs.langmuir.8b03528.pdf\n",
      "Paper 019: 019.jz3000036.pdf\n",
      "Paper 033: 033.aenm.201500285.pdf\n",
      "Paper 028: 028.jecs.A1100-6.pdf\n",
      "Paper 010: 010.jz101391r.pdf\n",
      "Paper 086: 086.pnas.2310714120.ms.pdf\n",
      "Paper 045: 045.acs.macromol.7b02573.pdf\n",
      "Paper 024: 024.jp310422q.pdf\n",
      "Paper 025: 025.commmat_4952.pdf\n",
      "Paper 056: 056.jcp.5.0047656.pdf\n",
      "Paper 057: 057.1-s2.0-S0167663621001502-main.pdf\n",
      "Paper 065: 065.1-s2.0-S0378775321009617-main.pdf\n",
      "Paper 062: 062.jacs.1c04272.pdf\n",
      "Paper 076: 076.PhysRevApplied.18.054031.pdf\n",
      "Paper 077: 077.acsanm.2c05257.pdf\n",
      "Paper 029: 029.jp410861h.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_main_versions(directory):\n",
    "    main_versions = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\") and filename.startswith(tuple(str(num) for num in range(10))):\n",
    "            if \"_si\" not in filename and \"_SM\" not in filename and \"-si\" not in filename and \"-mmc1\" not in filename and \".sapp\" not in filename:\n",
    "                paper_number = filename.split(\".\")[0]\n",
    "                if paper_number not in main_versions:\n",
    "                    main_versions[paper_number] = filename\n",
    "    return main_versions\n",
    "\n",
    "# Example usage:\n",
    "directory = \"published\"\n",
    "main_versions = find_main_versions(directory)\n",
    "print(\"Main versions of papers:\")\n",
    "for paper_number, filename in main_versions.items():\n",
    "    print(f\"Paper {paper_number}: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df07b10-7638-4f86-ae35-21e7cfbff6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main versions of papers:\n",
      "Paper 001: 001.nar-6047.full.pdf\n",
      "Paper 002: 002.BioPhysJ-2006-1463.pdf\n",
      "Paper 003: 003.NanoSciNanoTech.707.pdf\n",
      "Paper 004: 004.jbc-8829-36.pdf\n",
      "Paper 005: 005.jbc-15835-46.pdf\n",
      "Paper 006: 006.BioChem.bi901283p.pdf\n",
      "Paper 007: 007.cphc_201000528.pdf\n",
      "Paper 008: 008.JChemPhys_133_134114.pdf\n",
      "Paper 009: 009.jbc-37753-61.pdf\n",
      "Paper 010: 010.jz101391r.pdf\n",
      "Paper 011: 011.c0cp01549k.pdf\n",
      "Paper 012: 012.jz200453u.pdf\n",
      "Paper 013: 013.nl104227t.pdf\n",
      "Paper 014: 014.ct200211b.pdf\n",
      "Paper 015: 015.jz200760n.pdf\n",
      "Paper 016: 016.pnas.1108073108.pdf\n",
      "Paper 017: 017.jp209541e.pdf\n",
      "Paper 018: 018.jz201612y.pdf\n",
      "Paper 019: 019.jz3000036.pdf\n",
      "Paper 020: 020.jp301610b.pdf\n",
      "Paper 021: 021.jp306473u.pdf\n",
      "Paper 022: 022.jp309693d.pdf\n",
      "Paper 023: 023.025248JCP.pdf\n",
      "Paper 024: 024.jp310422q.pdf\n",
      "Paper 025: 025.commmat_4952.pdf\n",
      "Paper 026: 026.066401JCP.pdf\n",
      "Paper 027: 027.jz500260s.pdf\n",
      "Paper 028: 028.jecs.A1100-6.pdf\n",
      "Paper 029: 029.jp410861h.pdf\n",
      "Paper 030: 030.science.831.full.pdf\n",
      "Paper 031: 031.C4CP05316H.pdf\n",
      "Paper 032: 032.nature14327.pdf\n",
      "Paper 033: 033.aenm.201500285.pdf\n",
      "Paper 034: 034.c5cp02951a.pdf\n",
      "Paper 035: 035.nl5b02078.pdf\n",
      "Paper 036: 036.c6cp03940e1.pdf\n",
      "Paper 037: 037.jp6b04264.pdf\n",
      "Paper 038: 038.JECS-2017-Wujcik-A18-27.pdf\n",
      "Paper 039: 039.c6cp06889h.pdf\n",
      "Paper 040: 040.nlE7b00249.pdf\n",
      "Paper 041: 041.acs.jpcc.7b05153.pdf\n",
      "Paper 042: 042.s41467-017-02410-6.pdf\n",
      "Paper 043: 043.PhysRevLett.120.023901.pdf\n",
      "Paper 044: 044.jacs.7b11891.pdf\n",
      "Paper 045: 045.acs.macromol.7b02573.pdf\n",
      "Paper 046: 046.J. Electrochem. Soc.-2018-Wang-A3487-95.pdf\n",
      "Paper 047: 047.qt3xn0326x.pdf\n",
      "Paper 048: 048.jacs.8b09743.pdf\n",
      "Paper 049: 049.acs.langmuir.8b03528.pdf\n",
      "Paper 050: 050.1.5109468.pdf\n",
      "Paper 051: 051.acs.jpclett.9b01835.pdf\n",
      "Paper 052: 052.j.cplett.2019.136811.pdf\n",
      "Paper 053: 053.acsenergylett.0c00643.pdf\n",
      "Paper 054: 054.1-s2.0-S1369702120303382-main.pdf\n",
      "Paper 055: 055.s41560-021-00783-z.pdf\n",
      "Paper 056: 056.jcp.5.0047656.pdf\n",
      "Paper 057: 057.1-s2.0-S0167663621001502-main.pdf\n",
      "Paper 058: 058.eabe2265.full.pdf\n",
      "Paper 059: 059.s41467-021-23603-0.pdf\n",
      "Paper 060: 060.jcp5.0054314.pdf\n",
      "Paper 061: 061.acs.nanolett.1c01502.pdf\n",
      "Paper 062: 062.jacs.1c04272.pdf\n",
      "Paper 063: 063.PhysRevLett.127.096801.pdf\n",
      "Paper 064: 064.acs.jpclett.1c02609.ms.pdf\n",
      "Paper 065: 065.1-s2.0-S0378775321009617-main.pdf\n",
      "Paper 066: 066.PhysRevLett.127.237402.pdf\n",
      "Paper 067: 067.1-s2.0-S2666386421004537-main.pdf\n",
      "Paper 068: 068.acsenergylett.1c02723.pdf\n",
      "Paper 069: 069.d1ee03422g.pdf\n",
      "Paper 070: 070.acs.nanolett.2c00047.pdf\n",
      "Paper 071: 071.acs.jpclett.2c00770.pdf\n",
      "Paper 072: 072.pnas.2200392119.pdf\n",
      "Paper 073: 073.acsnano.2c04595.pdf\n",
      "Paper 074: 074.acs.chemmater.2c00292.pdf\n",
      "Paper 075: 075.acs.jpclett.2c01020.pdf\n",
      "Paper 076: 076.PhysRevApplied.18.054031.pdf\n",
      "Paper 077: 077.acsanm.2c05257.pdf\n",
      "Paper 078: 078.d2nr05732h.ms.pdf\n",
      "Paper 079: 079.acs.jpcb.2c08843.ms.pdf\n",
      "Paper 080: 080.acs.jpclett.2c03942.pdf\n",
      "Paper 081: 081.s41467-023-37857-3.pdf\n",
      "Paper 082: 082.s41563-023-01535-y.pdf\n",
      "Paper 083: 083.acs.nanolett.3c01825.ms.pdf\n",
      "Paper 084: 084.acsami.3c09627.pdf\n",
      "Paper 085: 085.acsami.3c07224.ms.pdf\n",
      "Paper 086: 086.pnas.2310714120.ms.pdf\n",
      "Paper 087: 087.jacs.3c05093.ms.pdf\n",
      "Paper 088: 088.anie202316786-ms.pdf\n",
      "Sup versions of papers:\n",
      "Paper 006: 006.BioChem.bi901283p_Sm.pdf\n",
      "Paper 007: 007.cphc_201000528_sm_miscellaneous_information.pdf\n",
      "Paper 008: 008.JChemPhys_133_134114_SM.pdf\n",
      "Paper 009: 009.jbc-37753-61_SM.pdf\n",
      "Paper 011: 011.c0cp01549k_SM.pdf\n",
      "Paper 012: 012.jz200453u_si_001.pdf\n",
      "Paper 013: 013.nl104227t_si_002.pdf\n",
      "Paper 015: 015.jz200760n_si_001.pdf\n",
      "Paper 016: 016.pnas.1108073108_SI.pdf\n",
      "Paper 017: 017.jp209541e_si_001.pdf\n",
      "Paper 018: 018.jz201612y_si_001.pdf\n",
      "Paper 019: 019.jz3000036_si_001.pdf\n",
      "Paper 020: 020.jp301610b_si_001.pdf\n",
      "Paper 021: 021.jp306473u_si_001.pdf\n",
      "Paper 024: 024.jp310422q_si_001.pdf\n",
      "Paper 027: 027.jz500260s_si.pdf\n",
      "Paper 029: 029.jp410861h_si_001.pdf\n",
      "Paper 030: 030.science.831.SM.pdf\n",
      "Paper 032: 032.nature14327-s1.pdf\n",
      "Paper 034: 034.c5cp02951a.SM.pdf\n",
      "Paper 035: 035.nl5b02078_si_001.pdf\n",
      "Paper 036: 036.c6cp03940e1_si.pdf\n",
      "Paper 037: 037.jp6b04264_si_001.pdf\n",
      "Paper 039: 039.c6cp06889h1_si.pdf\n",
      "Paper 040: 040.nlE7b00249_si.pdf\n",
      "Paper 041: 041.acs.jp7b05153_si_001.pdf\n",
      "Paper 042: 042.s41467-017-02410-6-SI.pdf\n",
      "Paper 043: 043.PhysRevLett.120.023901-SI.pdf\n",
      "Paper 044: 044.ja7b11891_si_001.pdf\n",
      "Paper 045: 045.ma7b02573_si_001.pdf\n",
      "Paper 046: 046.J. Electrochem. Soc.-2018-Wang-A3487-95-SI.pdf\n",
      "Paper 048: 048.ja8b09743_si_001.pdf\n",
      "Paper 049: 049.acs.langmuir.8b03528_si_001.pdf\n",
      "Paper 050: 050.1.5109468-sm.pdf\n",
      "Paper 051: 051.jz9b01835_si_001.pdf\n",
      "Paper 053: 053.acsenergylett.0c00643.si.pdf\n",
      "Paper 054: 054.1-s2.0-S1369702120303382-mmc1.pdf\n",
      "Paper 055: 055.s41560-021-00783-z-SI.pdf\n",
      "Paper 056: 056.jcp.5.0047656-si.pdf\n",
      "Paper 058: 058.abe2265_SM.pdf\n",
      "Paper 059: 059.s41467_2021_23603_MOESM1_ESM.pdf;059.s41467_2021_23603_MOESM5_ESM.pdf\n",
      "Paper 060: 060.jcp5.0054314-si.pdf\n",
      "Paper 061: 061.nl1c01502_si_001.pdf\n",
      "Paper 062: 062.ja1c04272_si_001.pdf\n",
      "Paper 063: 063.PhysRevLett.127.096801-si.pdf\n",
      "Paper 064: 064.acs.jpclett.1c02609.si.pdf\n",
      "Paper 065: 065.1-s2.0-S0378775321009617-si.pdf\n",
      "Paper 066: 066.PhysRevLett.127.237402.si.pdf\n",
      "Paper 067: 067.1-s2.0-S2666386421004537-mmc1.pdf\n",
      "Paper 068: 068.acsenergylett.1c02723_si.pdf\n",
      "Paper 069: 069.d1ee03422g.si.pdf\n",
      "Paper 070: 070.acs.nanolett.2c00047.si.pdf\n",
      "Paper 071: 071.jz2c00770_si_001.pdf\n",
      "Paper 072: 072.pnas.2200392119.sapp.pdf\n",
      "Paper 073: 073.acsnano.2c04595_si_001.pdf\n",
      "Paper 075: 075.jz2c01020_si_002.pdf;075.jz2c01020_si_001.pdf\n",
      "Paper 077: 077.an2c05257_si_001.pdf\n",
      "Paper 078: 078.d2nr05732h.si.pdf\n",
      "Paper 079: 079.acs.jpcb.2c08843.si.pdf\n",
      "Paper 080: 080.acs.jpclett.2c03942.si.1.pdf;080.acs.jpclett.2c03942.si.2.pdf\n",
      "Paper 081: 081.41467_2023_37857_MOESM1_ESM.pdf\n",
      "Paper 082: 082.s41563-023-01535-y_ESM.pdf\n",
      "Paper 083: 083.acs.nanolett.3c01825.si.pdf\n",
      "Paper 084: 084.acsami.3c09627_si_001.pdf\n",
      "Paper 085: 085.acsami.3c07224.si.pdf\n",
      "Paper 086: 086.pnas.2310714120.sapp.pdf\n",
      "Paper 087: 087.jacs.3c05093.si.pdf\n",
      "Paper 088: 088.anie202316786-si.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_main_and_supplementary_versions(directory):\n",
    "    main_versions = {}\n",
    "    supplementary_versions = {}\n",
    "    for paper_number in range(1, 89):  # Loop from 1 to 88\n",
    "        padded_number = str(paper_number).zfill(3)  # Zero-pad the number to ensure three digits\n",
    "        main_file = None\n",
    "        sup_file1 = None\n",
    "        sup_file2 = None\n",
    "        count = 0\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.startswith(padded_number) and filename.endswith(\".pdf\"):\n",
    "                count += 1\n",
    "                if not any(keyword in filename for keyword in [\"_si\", \"_SM\", \"-si\", \"-mmc1\", \".sapp\", \"-s1\", \".SM\", \".si\", \"_sm\", \"_Sm\", \"_SI\", \"-SI\", \"-sm\", \"_ESM\"]):\n",
    "                    main_file = filename\n",
    "                    # break  # Found main version, exit loop\n",
    "                else:\n",
    "                    if sup_file1:\n",
    "                        sup_file2 = filename\n",
    "                    else:\n",
    "                        sup_file1 = filename\n",
    "        if main_file:\n",
    "            main_versions[padded_number] = main_file\n",
    "        if sup_file1:\n",
    "            if sup_file2:\n",
    "                supplementary_versions[padded_number] = sup_file1 + \";\" + sup_file2\n",
    "                if count != 3:\n",
    "                    raise ValueError(f\"File number does not checkout 3 for {padded_number}\")\n",
    "            else:\n",
    "                supplementary_versions[padded_number] = sup_file1\n",
    "                if count != 2:\n",
    "                    raise ValueError(f\"File number does not checkout 2 for {padded_number}\")\n",
    "        else:\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"File number does not checkout 1 for {padded_number}\")\n",
    "    return main_versions, supplementary_versions\n",
    "\n",
    "# Example usage:\n",
    "directory = \"published\"\n",
    "main_versions, supplementary_versions = find_main_and_supplementary_versions(directory)\n",
    "print(\"Main versions of papers:\")\n",
    "for paper_number, filename in main_versions.items():\n",
    "    print(f\"Paper {paper_number}: {filename}\")\n",
    "\n",
    "print(\"Sup versions of papers:\")\n",
    "for paper_number, file_path in supplementary_versions.items():\n",
    "    print(f\"Paper {paper_number}: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2baa533-df47-49c9-b9b4-8d47ea725ab5",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW HERE IS THE AUTOMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52efd26d-0344-4730-b137-27715bf8dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "def extract_dois_from_pdf(pdf_file_path):\n",
    "    dois = []\n",
    "    with pdfplumber.open(pdf_file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Use regex to find DOI patterns\n",
    "            doi_matches = re.findall(r'\\b(10\\.\\d{4,}(?:\\.\\d+)*\\/[-._;()\\/:A-Z0-9]+)\\b', text, re.IGNORECASE) \n",
    "            for match in doi_matches:\n",
    "                dois.append(match)\n",
    "    return dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5516abc0-e575-47e9-827e-bbc0bfa7de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "name_to_account = {\n",
    "    'Tod A. Pascal': 'Tod',\n",
    "    'Tod Pascal': 'Tod',\n",
    "}\n",
    "\n",
    "def replace_with_dictionary(array, dictionary):\n",
    "    # Iterate over each string in the array\n",
    "    for i in range(len(array)):\n",
    "        # If the string is a key in the dictionary, replace it with the corresponding value\n",
    "        if array[i] in dictionary:\n",
    "            array[i] = dictionary[array[i]]\n",
    "    return array\n",
    "\n",
    "def fetch_data(doi):\n",
    "    \"\"\"Fetch publication data from CrossRef API.\"\"\"\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['message']\n",
    "    else:\n",
    "        print(\"Failed to fetch data.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def create_files(pub_data, dir_name, source_dir, main_file, sup_file1, sup_file2):\n",
    "    \"\"\"Create directory and files based on publication data.\"\"\"\n",
    "    # Ensure valid filenames\n",
    "    directory = \"out\"\n",
    "    sub_directory = dir_name.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace('\"', '').replace(':', '_').replace('?', '')\n",
    "    valid_dir_name = os.path.join(directory, sub_directory)\n",
    "    os.makedirs(valid_dir_name, exist_ok=True)\n",
    "\n",
    "    # Extracting and formatting author list to include only first names\n",
    "    authors_source = [f\"{author.get('given', '')} {author.get('family', '')}\" for author in pub_data.get('author', [])]\n",
    "    authors = authors_source.copy()\n",
    "    authors = replace_with_dictionary(authors, name_to_account)\n",
    "    authors_md = \"\\n- \".join([\"\"] + authors)  # Markdown list format\n",
    "    \n",
    "    # Format publication date correctly\n",
    "    pub_date_parts = pub_data.get('published-print', pub_data.get('published-online', {'date-parts': [[0]]}))['date-parts'][0]\n",
    "    if len(pub_date_parts) == 3:  # Full date available\n",
    "        formatted_pub_date = f\"{pub_date_parts[0]:04d}-{pub_date_parts[1]:02d}-{pub_date_parts[2]:02d}T00:00:00Z\"\n",
    "    elif len(pub_date_parts) == 2:  # Only year and month available\n",
    "        formatted_pub_date = f\"{pub_date_parts[0]:04d}-{pub_date_parts[1]:02d}-01T00:00:00Z\"\n",
    "    else:  # Only year available\n",
    "        formatted_pub_date = f\"{pub_date_parts[0]:04d}-01-01T00:00:00Z\"\n",
    "\n",
    "    main_link = \"\"\n",
    "    if main_file:\n",
    "        shutil.copy2(os.path.join(source_dir, main_file), valid_dir_name)\n",
    "        main_link = f\"\"\"- name: Main Paper\n",
    "  url: \"publication/{sub_directory}/{main_file}\" \"\"\"\n",
    "    sup_link1 = \"\"\n",
    "    if sup_file1:\n",
    "        shutil.copy2(os.path.join(source_dir, sup_file1), valid_dir_name)\n",
    "        sup_link1 = f\"\"\"- name: Supporting Material\n",
    "  url: \"publication/{sub_directory}/{sup_file1}\" \"\"\"\n",
    "    sup_link2 = \"\"\n",
    "    if sup_file2:\n",
    "        shutil.copy2(os.path.join(source_dir, sup_file2), valid_dir_name)\n",
    "        sup_link2 = f\"\"\"- name: Supporting Material 2\n",
    "  url: \"publication/{sub_directory}/{sup_file2}\" \"\"\"\n",
    "    \n",
    "    # Edge Case during parsing:\n",
    "    publication = pub_data.get('container-title', [''])\n",
    "    if len(publication) == 0:\n",
    "        publication = ['']\n",
    "    # Index.md content\n",
    "    index_content = f\"\"\"---\n",
    "title: \"{pub_data.get('title', [''])[0]}\"\n",
    "authors:{authors_md}\n",
    "date: \"{formatted_pub_date}\"\n",
    "doi: \"{pub_data.get('DOI', '')}\"\n",
    "abstract: \"{pub_data.get('abstract', '').replace('\\n', ' ')}\"\n",
    "links:\n",
    "{main_link}\n",
    "{sup_link1}\n",
    "{sup_link2}\n",
    "publication: \"{publication[0]}\"\n",
    "publication_types: [\"article-journal\"]\n",
    "---\n",
    "\n",
    "Add the publication's full text or supplementary notes here.\n",
    "\"\"\"\n",
    "    with open(os.path.join(valid_dir_name, \"index.md\"), \"w\", encoding='utf-8') as f:\n",
    "        f.write(index_content)\n",
    "\n",
    "    # Prepare full names for citation\n",
    "    bib_authors = \", \".join(authors_source)\n",
    "    bib_content = f\"\"\"@article{{{pub_data.get('DOI', '').replace('/', '_')},\n",
    "  title = {{{pub_data.get('title', [''])[0]}}},\n",
    "  author= {{{bib_authors}}},\n",
    "  journal = {{{publication[0]}}},\n",
    "  year    = {pub_date_parts[0]},\n",
    "  volume  = {pub_data.get('volume', '')},\n",
    "  number  = {pub_data.get('issue', '')},\n",
    "  doi     = {{{pub_data.get('DOI', '')}}},\n",
    "  url     = {{{pub_data.get('URL', '')}}}\n",
    "}}\n",
    "\"\"\"\n",
    "    with open(os.path.join(valid_dir_name, \"cite.bib\"), \"w\", encoding='utf-8') as f:\n",
    "        f.write(bib_content)\n",
    "\n",
    "    print(f\"Files generated in directory: {valid_dir_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39871dd5-a9f7-4837-a4ea-cfb312525fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_common_string(strings):\n",
    "    # Count occurrences of each string\n",
    "    counts = Counter(strings)\n",
    "    # Find the most common string\n",
    "    most_common = max(counts, key=counts.get)\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52f9fa3-c3b8-4bd3-817b-c173853c2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_files_with_main_and_supplementary_versions(directory):\n",
    "    main_versions = {}\n",
    "    supplementary_versions = {}\n",
    "    for paper_number in range(1, 89):  # Loop from 1 to 88\n",
    "        padded_number = str(paper_number).zfill(3)  # Zero-pad the number to ensure three digits\n",
    "        main_file = None\n",
    "        sup_file1 = None\n",
    "        sup_file2 = None\n",
    "        count = 0\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.startswith(padded_number) and filename.endswith(\".pdf\"):\n",
    "                count += 1\n",
    "                if not any(keyword in filename for keyword in [\"_si\", \"_SM\", \"-si\", \"-mmc1\", \".sapp\", \"-s1\", \".SM\", \".si\", \"_sm\", \"_Sm\", \"_SI\", \"-SI\", \"-sm\", \"_ESM\"]):\n",
    "                    main_file = filename\n",
    "                    # break  # Found main version, exit loop\n",
    "                else:\n",
    "                    if sup_file1:\n",
    "                        sup_file2 = filename\n",
    "                    else:\n",
    "                        sup_file1 = filename\n",
    "        if main_file:\n",
    "            main_versions[padded_number] = main_file\n",
    "        if sup_file1:\n",
    "            if sup_file2:\n",
    "                supplementary_versions[padded_number] = sup_file1 + \";\" + sup_file2\n",
    "                if count != 3:\n",
    "                    raise ValueError(f\"File number does not checkout 3 for {padded_number}\")\n",
    "            else:\n",
    "                supplementary_versions[padded_number] = sup_file1\n",
    "                if count != 2:\n",
    "                    raise ValueError(f\"File number does not checkout 2 for {padded_number}\")\n",
    "        else:\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"File number does not checkout 1 for {padded_number}\")\n",
    "\n",
    "        dois = extract_dois_from_pdf(os.path.join(directory, main_file))\n",
    "        print(dois)\n",
    "        if len(dois) < 1:\n",
    "            print(f\"No DOI possible for paper {padded_number}\")\n",
    "            continue\n",
    "        doi = most_common_string(dois)\n",
    "        pub_data = fetch_data(doi)\n",
    "        \n",
    "        # Use title for directory name, or DOI if title is unavailable\n",
    "        dir_name = pub_data.get('DOI').split('/')[1]\n",
    "        create_files(pub_data, dir_name, directory, main_file, sup_file1, sup_file2)\n",
    "        extract_and_mark_figures(os.path.join(directory, main_file), dir_name)\n",
    "        \n",
    "    \n",
    "    return main_versions, supplementary_versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab3e646-c2e8-459b-8350-88ea059792d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_files_with_main_and_supplementary_versions_test(directory):\n",
    "    main_versions = {}\n",
    "    supplementary_versions = {}\n",
    "    for paper_number in range(1, 2):  # Loop from 1 to 88\n",
    "        padded_number = str(paper_number).zfill(3)  # Zero-pad the number to ensure three digits\n",
    "        main_file = None\n",
    "        sup_file1 = None\n",
    "        sup_file2 = None\n",
    "        count = 0\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.startswith(padded_number) and filename.endswith(\".pdf\"):\n",
    "                count += 1\n",
    "                if not any(keyword in filename for keyword in [\"_si\", \"_SM\", \"-si\", \"-mmc1\", \".sapp\", \"-s1\", \".SM\", \".si\", \"_sm\", \"_Sm\", \"_SI\", \"-SI\", \"-sm\", \"_ESM\"]):\n",
    "                    main_file = filename\n",
    "                    # break  # Found main version, exit loop\n",
    "                else:\n",
    "                    if sup_file1:\n",
    "                        sup_file2 = filename\n",
    "                    else:\n",
    "                        sup_file1 = filename\n",
    "        if main_file:\n",
    "            main_versions[padded_number] = main_file\n",
    "        if sup_file1:\n",
    "            if sup_file2:\n",
    "                supplementary_versions[padded_number] = sup_file1 + \";\" + sup_file2\n",
    "                if count != 3:\n",
    "                    raise ValueError(f\"File number does not checkout 3 for {padded_number}\")\n",
    "            else:\n",
    "                supplementary_versions[padded_number] = sup_file1\n",
    "                if count != 2:\n",
    "                    raise ValueError(f\"File number does not checkout 2 for {padded_number}\")\n",
    "        else:\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"File number does not checkout 1 for {padded_number}\")\n",
    "\n",
    "        dois = extract_dois_from_pdf(os.path.join(directory, main_file))\n",
    "        print(dois)\n",
    "        if len(dois) < 1:\n",
    "            print(f\"No DOI possible for paper {padded_number}\")\n",
    "            continue\n",
    "        doi = most_common_string(dois)\n",
    "        pub_data = fetch_data(doi)\n",
    "        \n",
    "        # Use title for directory name, or DOI if title is unavailable\n",
    "        dir_name = pub_data.get('DOI').split('/')[1]\n",
    "        create_files(pub_data, dir_name, directory, main_file, sup_file1, sup_file2)\n",
    "        extract_and_mark_figures(os.path.join(directory, main_file), \"test\")\n",
    "    \n",
    "    return main_versions, supplementary_versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bafbe1-6654-4bfc-afe3-d3e3c886cb87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_files_with_main_and_supplementary_versions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m main_versions, supplementary_versions \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_files_with_main_and_supplementary_versions\u001b[49m(directory)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain versions of papers:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paper_number, filename \u001b[38;5;129;01min\u001b[39;00m main_versions\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_files_with_main_and_supplementary_versions' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "directory = \"published\"\n",
    "main_versions, supplementary_versions = create_files_with_main_and_supplementary_versions(directory)\n",
    "print(\"Main versions of papers:\")\n",
    "for paper_number, filename in main_versions.items():\n",
    "    print(f\"Paper {paper_number}: {filename}\")\n",
    "\n",
    "print(\"Sup versions of papers:\")\n",
    "for paper_number, file_path in supplementary_versions.items():\n",
    "    print(f\"Paper {paper_number}: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772dee79-934a-4184-8df2-fd5ddd8c4577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.1021/bi901283p']\n",
      "Files generated in directory: out/bi901283p\n"
     ]
    },
    {
     "ename": "FileDataError",
     "evalue": "'test' is no file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileDataError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_509/2010746790.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain_versions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupplementary_versions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_files_with_main_and_supplementary_versions_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Main versions of papers:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpaper_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmain_versions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mPaper \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mpaper_number\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_509/4241454786.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Use title for directory name, or DOI if title is unavailable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdir_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpub_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DOI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcreate_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpub_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msup_file1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msup_file2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mextract_and_mark_figures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmain_versions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupplementary_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_509/1034886806.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(pdf_path, output_directory)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_and_mark_figures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfigure_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create the output directory if it doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/webscraping/lib/python3.12/site-packages/fitz/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2808\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2810\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count_fz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m             \u001b[0mJM_mupdf_show_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJM_mupdf_show_errors_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileDataError\u001b[0m: 'test' is no file"
     ]
    }
   ],
   "source": [
    "directory = \"test\"\n",
    "main_versions, supplementary_versions = create_files_with_main_and_supplementary_versions_test(directory)\n",
    "print(\"Main versions of papers:\")\n",
    "for paper_number, filename in main_versions.items():\n",
    "    print(f\"Paper {paper_number}: {filename}\")\n",
    "\n",
    "print(\"Sup versions of papers:\")\n",
    "for paper_number, file_path in supplementary_versions.items():\n",
    "    print(f\"Paper {paper_number}: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7506e2-c5fc-453a-94b8-c0a9c0093788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure_1.png from page 2 at ./test/figure_1.png\n",
      "Saved figure_2.png from page 2 at ./test/figure_2.png\n",
      "Saved figure_3.png from page 3 at ./test/figure_3.png\n",
      "Saved figure_4.png from page 4 at ./test/figure_4.png\n",
      "Saved figure_5.png from page 5 at ./test/figure_5.png\n",
      "Saved figure_6.png from page 5 at ./test/figure_6.png\n",
      "Saved figure_7.png from page 5 at ./test/figure_7.png\n",
      "Saved figure_8.png from page 6 at ./test/figure_8.png\n",
      "Saved figure_9.png from page 6 at ./test/figure_9.png\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_and_mark_figures(pdf_path, output_directory):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    figure_counter = 1\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for page_number in range(len(doc)):\n",
    "        page = doc[page_number]\n",
    "        image_list = page.get_images(full=True)  # Image references\n",
    "\n",
    "        # Extract and save each image\n",
    "        for img_index, img_info in enumerate(image_list):\n",
    "            xref = img_info[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "\n",
    "            image_filename = f\"figure_{figure_counter}.{image_ext}\"\n",
    "            image_path = os.path.join(output_directory, image_filename)\n",
    "\n",
    "            with open(image_path, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "\n",
    "            print(f\"Saved {image_filename} from page {page_number + 1} at {image_path}\")\n",
    "            figure_counter += 1\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "pdf_path = './test/001.BioChem.bi901283p.pdf'\n",
    "output_directory = './test'\n",
    "extract_and_mark_figures(pdf_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870ffec-38e3-4f3f-958f-42d1e84bd32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
